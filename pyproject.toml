[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "Concept_Drift_Rapid_Retraining"
version = "1.0.0"
description = "Federated Learning with PyTorch and Flower (Quickstart Example)"
license = "Apache-2.0"

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.flwr.app]
publisher = "flwrlabs"

[tool.flwr.app.components]
serverapp = "src.server_app:app"
clientapp = "src.client_app:app"

[tool.flwr.app.config]
num-of-clients = 10
num-server-rounds = 100
num-batches-each-round = 20
fraction-evaluate = 1
local-epochs = 3
learning-rate = 0.001
batch-size = 128
# options: fashion_mnist, mnist
dataset-name = "mnist"
data-loader-alpha = 0.9
prepare-dataset = false
dataset-folder-path = "src/data/clients_dataset"

# Drift configuration
drift-start-round = 20
incremental-drift-rounds = '{"20": 0.2, "40": 0.4, "60": 0.6, "80": 0.8}'
drift-end-round = 80
drift-clients = "[1,5,7]"
abrupt-drift-labels-swap = '[{"label1": 1, "label2": 2},{"label1": 5, "label2": 7}]'
# abrupt-drift-labels-swap = '[{"label1": 0, "label2": 2},{"label1": 5, "label2": 7}]'
drift-dataset-indexes-folder-path = "src/data/clients_drift_dataset_indexes"
remaining-dataset-folder-path = "src/data/clients_remaining_dataset"
drifted-dataset-folder-path = "src/data/clients_drifted_dataset"

# unlearning settings: drift-case, retraining-case, rapid-retraining-case, fedau-case, fluid-case
mode = "drift-case"

[tool.flwr.federations]
default = "local-simulation"

[tool.flwr.federations.local-simulation]
options.num-supernodes = 10

[tool.flwr.federations.local-simulation-gpu]
options.num-supernodes = 10
options.backend.client-resources.num-cpus = 2 # each ClientApp assumes to use 2CPUs
options.backend.client-resources.num-gpus = 0.2 # at most 5 ClientApp will run in a given GPU
